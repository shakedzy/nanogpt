{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "from tqdm import tqdm\n",
    "from torch import nn\n",
    "from typing import cast\n",
    "from nanogpt.data import Data\n",
    "from nanogpt.encoder import CharacterLevelEncoder, TiktokenBasedEncoder\n",
    "from nanogpt.gpt import NanoGPT\n",
    "from nanogpt.blm import BigramLanguageModel\n",
    "from nanogpt.utils import path_to_resource_file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data\n",
    "The data used for training in a set of all Shakespeare's plays, taken from The Gutenberg Project: [The Complete Works of William Shakespeare](https://www.gutenberg.org/ebooks/100).\n",
    "\n",
    "In addition, I've added a special token (the character §) at the beginning of each play, thus we can refer to this token as a _\"start-of-play\"_ token."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_default_device('mps')  # Running on a Mac\n",
    "torch.manual_seed(1337)          # Reproducible results\n",
    "\n",
    "# Load data\n",
    "data_file = 'gutenberg_shakespeare_st.txt'\n",
    "with open(path_to_resource_file(data_file), \"r\") as f:\n",
    "    text = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to estimate the loss of a model on a dataset\n",
    "@torch.no_grad()\n",
    "def estimate_loss(model: nn.Module, data: Data, batch_size: int, block_size: int, *, eval_iters: int = 100):\n",
    "    out = {}\n",
    "    model.eval()\n",
    "    for split in ['train', 'test']:\n",
    "        losses = torch.zeros(eval_iters)\n",
    "        for k in range(eval_iters):\n",
    "            X, Y = data.get_batch(split, batch_size=batch_size, block_size=block_size)  # type: ignore\n",
    "            _, loss = model(X, Y)\n",
    "            losses[k] = loss.item()\n",
    "        out[split] = losses.mean()\n",
    "    model.train()\n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A simple Bigram Language Model\n",
    "The first simple model in Andrej's video, used with a simple character-level encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of tokens: 101\n"
     ]
    }
   ],
   "source": [
    "# Create a character-level encoder and a dataset\n",
    "encoder = CharacterLevelEncoder(text)\n",
    "data = Data(torch.tensor(encoder.encode(text), dtype=torch.long), split=.9)\n",
    "print('Number of tokens:', len(encoder))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs:\n",
      "torch.Size([4, 8])\n",
      "tensor([[61,  2, 68, 56, 56, 54, 72, 62],\n",
      "        [62, 65, 65, 58, 72, 23,  1, 43],\n",
      "        [22,  2, 66, 78, 72, 58, 65, 59],\n",
      "        [54, 66,  2, 61, 62, 72,  2, 31]], device='mps:0')\n",
      "targets:\n",
      "torch.Size([4, 8])\n",
      "tensor([[ 2, 68, 56, 56, 54, 72, 62, 68],\n",
      "        [65, 65, 58, 72, 23,  1, 43, 54],\n",
      "        [ 2, 66, 78, 72, 58, 65, 59,  2],\n",
      "        [66,  2, 61, 62, 72,  2, 31, 71]], device='mps:0')\n",
      "---------\n",
      "Loss: 5.3841872215271\n",
      "torch.Size([4, 8, 101])\n"
     ]
    }
   ],
   "source": [
    "# Taking a look at a batch from the data and an untrained model\n",
    "xb, yb = data.get_batch('train', 4, 8)\n",
    "print('inputs:')\n",
    "print(xb.shape)\n",
    "print(xb)\n",
    "print('targets:')\n",
    "print(yb.shape)\n",
    "print(yb)\n",
    "\n",
    "print('---------')\n",
    "blm = BigramLanguageModel(len(encoder))\n",
    "logits, loss = blm(xb, yb)\n",
    "print('Loss:', loss.item())\n",
    "print(logits.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "§83sedâRU,’CxXK\tbl—GoQW—TOuèc\tFEjr*…—GFÆ*’’œs.Fà[”4YuIz88H-9”gL4)y’,YC_U]yP]SÇ-TkqsIBIÇo’&tVXOwà—hOwO\n"
     ]
    }
   ],
   "source": [
    "# See what an untrained model generates after a new-story token\n",
    "token = encoder.encode('§')\n",
    "idx = torch.tensor([token], dtype=torch.long)\n",
    "print(encoder.decode(blm.generate(idx, max_new_tokens=100)[0].tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [04:10<00:00, 40.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train': tensor(2.5165, device='mps:0'), 'test': tensor(2.5311, device='mps:0')}\n"
     ]
    }
   ],
   "source": [
    "# Training\n",
    "batch_size = 32\n",
    "block_size = 8\n",
    "\n",
    "optimizer = torch.optim.AdamW(blm.parameters(), lr=1e-3)\n",
    "for _ in tqdm(range(10000)):\n",
    "    xb, yb = data.get_batch('train', batch_size=batch_size, block_size=block_size)\n",
    "    logits, loss = blm(xb, yb)\n",
    "    loss = cast(torch.Tensor, loss)\n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "print(estimate_loss(blm, data, batch_size=batch_size, block_size=block_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "§Himowis n wsine merurey dashed HANWIN FRenxe rson sindy ake agise s aten tesgh oilefffo.\n",
      "S\n",
      "ISWhe. wî\n"
     ]
    }
   ],
   "source": [
    "# Now let's see what happens after some training\n",
    "token = encoder.encode('§')\n",
    "idx = torch.tensor([token], dtype=torch.long)\n",
    "print(encoder.decode(blm.generate(idx, max_new_tokens=100)[0].tolist()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NanoGPT\n",
    "This version uses the NanoGPT model with the same character-level encoder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [14:39<00:00, 11.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train': tensor(1.8495, device='mps:0'), 'test': tensor(1.9291, device='mps:0')}\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "context_length = 32\n",
    "\n",
    "gpt = NanoGPT(vocab_size=len(encoder), embedding_size=64, context_length=context_length, num_heads=4, num_blocks=4, dropout=.2)\n",
    "\n",
    "# Training\n",
    "optimizer = torch.optim.AdamW(gpt.parameters(), lr=1e-3)\n",
    "for _ in tqdm(range(10000)):\n",
    "    xb, yb = data.get_batch('train', batch_size=batch_size, block_size=context_length)\n",
    "    logits, loss = gpt(xb, yb)\n",
    "    loss = cast(torch.Tensor, loss)\n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "print(estimate_loss(gpt, data, batch_size=batch_size, block_size=context_length))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPETCIUS SELYMAY.\n",
      "UDo I EDotho Yesiet, _’t human hoored,\n",
      " shackowe.\n",
      "\n",
      "\n",
      "PANAWN.\n",
      "Tith likes, your and see foulas. He e witwer.\n",
      "JUSWIAGeay will’s oneye cobrit, for his go bleald.\n",
      "\n",
      "FORTs GUILUCES.\n",
      "Your tander,\n",
      "Broother hon sengiesst.\n",
      "\n",
      "LEASERGEUS.\n",
      "Mastaster you His!\n",
      "\n",
      "FARITHS.\n",
      "Ater, with bead fir a him hereancr nnotuns?\n",
      "\n",
      "PEDIUS.\n",
      "Whould Ifull. The morve was shublinged foe torgh monese with haris,\n",
      "Yed partccitus itorme, ance fiel I bling ofise; a Old wa nd i hunrses o.\n",
      "LODIG.\n",
      "Thy us Conjey pat.\n",
      "\n",
      "\n",
      "IPARSTICO.\n",
      " to moix ved’s and with\n",
      "TH veraturch yofoys.\n",
      "\n",
      "HOTHSTALIA.\n",
      "y you with thou arsennting to a blodsle.\n",
      "\n",
      "Thou in epleveres Is hosceald ito with whears houne soris mage\n",
      "Which mifuls dom do theat. In, may the gost the I thath give s.\n",
      "\n",
      "BRERULESS.\n",
      "Fatrds ther m, so hare tharing Heninous.\n",
      "\n",
      "Bos tace toldge.\n",
      "\n",
      "ISTHAST.\n",
      "OYou beaved know spimest thit houm?\n",
      "\n",
      "FIRSSEPPELLOS.\n",
      "And, you shat bystouth.\n",
      "Mates sidrto me, you no thi chapppraip har’s. His ree yoe’d thin brom be to dm\n",
      "thou me I wile eso. And but los l"
     ]
    }
   ],
   "source": [
    "token = encoder.encode('§')\n",
    "idx = torch.tensor([token], dtype=torch.long)\n",
    "for token in gpt.generate(idx, max_new_tokens=1000):\n",
    "    print(encoder.decode(token[0].tolist()), end='', flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using a better tokenizer\n",
    "Now let's try this with the GPT-4o tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of tokens: 23544\n"
     ]
    }
   ],
   "source": [
    "# Create a character-level encoder and a dataset\n",
    "encoder = TiktokenBasedEncoder(text)\n",
    "data = Data(torch.tensor(encoder.encode(text), dtype=torch.long), split=.9)\n",
    "print('Number of tokens:', len(encoder))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [15:10<00:00, 10.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train': tensor(4.3664, device='mps:0'), 'test': tensor(5.6775, device='mps:0')}\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "context_length = 32\n",
    "\n",
    "gpt = NanoGPT(vocab_size=len(encoder), embedding_size=64, context_length=context_length, num_heads=4, num_blocks=4, dropout=.2)\n",
    "\n",
    "# Training\n",
    "optimizer = torch.optim.AdamW(gpt.parameters(), lr=1e-3)\n",
    "for _ in tqdm(range(10000)):\n",
    "    xb, yb = data.get_batch('train', batch_size=batch_size, block_size=context_length)\n",
    "    logits, loss = gpt(xb, yb)\n",
    "    loss = cast(torch.Tensor, loss)\n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "print(estimate_loss(gpt, data, batch_size=batch_size, block_size=context_length))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CYMBELINE.\n",
      "Nay, he here?\n",
      "\n",
      "THERSITES.\n",
      "It was evermore as a word, by her yet, I only.\n",
      "True, would haveuous, thy stake,\n",
      "No reprehending did put unto the Sun air.\n",
      "And having made the threat’st not not been silent hour,\n",
      "Belong capital fever when I went here to thing one place.\n",
      "\n",
      "KING RICHARD.\n",
      "No, rapier.\n",
      "\n",
      "TIMON.\n",
      "It is the docks, and mild visage upon your name, my chamber; or whisper\n",
      "me set away again and my likeness.\n",
      "\n",
      "CASSANIO.\n",
      "I have not any of mine eyes,\n",
      "My consent.\n",
      "By the offender-face, and sour and be not my fidelity, set thiev’d,\n",
      "And make his sin;\n",
      "His eldest son, does by chance._\n",
      "\n",
      "QUO, to chariot,\n",
      "Thus yet so she is cold as my France,\n",
      "Whose worst were bad a great King all the King\n",
      "To be avoided;\n",
      "And that rock would have promised; yet you are his\n",
      "That here pulls’d your accusers in love care\n",
      "Which to this I’ll find not appear against her.\n",
      "\n",
      "GLOUCESTER.\n",
      "Nay, thou art offered to your mercy thus thou, I was\n",
      "have.\n",
      "\n",
      "PETRUCHIO.\n",
      "We have my message, or else knew thou what we miss.\n",
      "Well, my revenge unto the news?\n",
      "\n",
      "MISTRESS QUICKLY.\n",
      "I’ll kill him both. But how now: plain.\n",
      "Yes, gather suggestion.\n",
      "\n",
      "MISTRESS QUICKLY.\n",
      "As I was enough. Here’s last.\n",
      "There is it with his fool and more gold.\n",
      "\n",
      "[_Exit._]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "§CYMBELINE.\n",
      "Well in Gonzalo John quit your error.\n",
      "\n",
      "OR.\n",
      "Madam, Helen for question: who daint, very foolish, is that\n",
      "pretty!\n",
      "\n",
      "GRIFFITH.\n",
      "A plain:\n",
      "We will not be it is returnful about him here: the good to your high, sir,\n",
      "He hath an thinking of these years\n",
      "That by my behalf of his timeless friends;\n",
      "And called me again.\n",
      "\n",
      "FIRSTIBAN.\n",
      "Heaven bless’d like not too long not so wish.\n",
      "Kill him, do it no.\n",
      "\n",
      "BENEDICK.\n",
      "One, a time only?\n",
      "\n",
      "LUCET.\n",
      "Ay, my him, Master Smooth, now, Charmian?\n",
      "\n",
      "DUKE.\n",
      "I cannot marry, if sir, sufferance of him to make\n",
      "Upon his silence; I think then which\n",
      "mist board, at thee still drown me thy courtesies can\n",
      "them; come off pray not he about thy steel, and be away;\n",
      "There is.\n",
      "I’ll rail to Caesar did well.\n",
      "Oritted early when I’ll drink.\n",
      "\n",
      "BARDOLPH.\n",
      "[_Aside._] Drawosed I was dead ELEANOR.\n",
      "DICK.\n",
      "Now, how being lacked him; I remember the fool ’twill have turn fixed. Nurses with thee to fright yourself again,\n",
      " Whilst gape to a man.\n",
      "\n",
      "DON PEDRO.\n",
      "Fear me, lords, you!\n",
      "O, any special madam, all she is the empress,\n",
      "with silkuble of prayer hath put up my true lovedow,\n",
      "Blowneeling\n",
      "But who done an Officer of the hatch\n",
      "Of princes made false in out of mind,\n",
      "Equal love Cæsar’s loss and experience.\n",
      "I do’t both served France for Bardolph?\n",
      "\n",
      "KENTLE BEances of Rosalindarus! Be love’s daughter?\n",
      "Is not such a soldier.\n",
      "Too from that better; curbs needs may be all the lightning, with me\n",
      "To me advise me to the little captain, I protest out the dish more foe.\n",
      "\n",
      "KING HENRY.\n",
      "[_Kneeling_.] Pray, let us by Caesar’s sheep of this morning and say, till he’s silence, grant with\n",
      "Do tears staunch.\n",
      "\n",
      "HEPH.\n",
      "Fetch me? Andronicus, I shall work; I do you at first; trust me another hither;\n",
      "Turn’d, I am ever broke this golden purpose, I am much well subscrib’d in ugly, who\n",
      "To pity our wars;\n",
      "Your Grace moves. And that will be endeared confronted off these suits from me thy head\n",
      "To lay my fool MESSALA.\n",
      "Let the best beheld each crest, that wretched world come with him\n",
      "            Theold trencherfellow-mad at his challenge of his letter of the purpose\n",
      "first’s, an inventory, to deliver the act of it.\n",
      "\n",
      "SHY.\n",
      "I am sure.\n",
      "\n",
      "Dost, look upon thee.\n",
      "\n",
      "ANTONY.\n",
      "None but begin for my lady, my look we have parting a wife of me welcome you, mellow, I have our countrymen.\n",
      "\n",
      "GONZALO.\n",
      "A grievous-lartius, has deceived, ’tis not yours of God is paid, pardon,\n",
      "Are now’s incest all of the King of the best;\n",
      "Whereinave of torment! Like I do wishation to him she had\n",
      "Hath after to show you"
     ]
    }
   ],
   "source": [
    "token = encoder.encode('§')\n",
    "idx = torch.tensor([token], dtype=torch.long)\n",
    "for token in gpt.generate(idx, max_new_tokens=1000):\n",
    "    print(encoder.decode(token[0].tolist()), end='', flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Let's retry, this time without the special _\"start-of-play\"_ token. what will be the difference?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "data_file = 'gutenberg_shakespeare.txt'\n",
    "with open(path_to_resource_file(data_file), \"r\") as f:\n",
    "    text = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of tokens: 23542\n"
     ]
    }
   ],
   "source": [
    "encoder = TiktokenBasedEncoder(text)\n",
    "data = Data(torch.tensor(encoder.encode(text), dtype=torch.long), split=.9)\n",
    "print('Number of tokens:', len(encoder))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [15:59<00:00, 10.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train': tensor(4.3474, device='mps:0'), 'test': tensor(5.6757, device='mps:0')}\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "context_length = 32\n",
    "\n",
    "gpt = NanoGPT(vocab_size=len(encoder), embedding_size=64, context_length=context_length, num_heads=4, num_blocks=4, dropout=.2)\n",
    "\n",
    "# Training\n",
    "optimizer = torch.optim.AdamW(gpt.parameters(), lr=1e-3)\n",
    "for _ in tqdm(range(10000)):\n",
    "    xb, yb = data.get_batch('train', batch_size=batch_size, block_size=context_length)\n",
    "    logits, loss = gpt(xb, yb)\n",
    "    loss = cast(torch.Tensor, loss)\n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "print(estimate_loss(gpt, data, batch_size=batch_size, block_size=context_length))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sir, is unbo._\n",
      "\n",
      " [_Kisses home._]\n",
      "\n",
      "CASSIUS\n",
      "EGEON\n",
      "Than it of Pembroke, a feather; ’tis out. They say’s power to seem in time and\n",
      "first”.\n",
      "\n",
      "PAGE.\n",
      "Adieu, welcome,\n",
      "And I’ll melt the other offences.\n",
      "Stay for him not obey in the last willingly honour shall alter,\n",
      "or precept [ided\n",
      "To see to be drawn been much hard sailor.\n",
      "\n",
      "GRATSWAIN.\n",
      "But, my lord!\n",
      "\n",
      "CLEOPATRA.\n",
      "Amen, good Captain.\n",
      "O Lord is he, why (God save\n",
      "The law! “how he meditrah? if thou rather merrily, most noble uncle do know’st have the world and still be never keep the officer. Shall Priam\n",
      "me would sing like a daughter.\n",
      "\n",
      "IACHIMO.\n",
      "’Tis not only to do not have be a lord is spirit,\n",
      "Our one of success! If he keep us,\n",
      "By the sooner have better than ’twere yet, my resolution, against our blows.\n",
      "\n",
      "CLOWN.\n",
      "I’ll tell him follow a cockc’d thee how com’st,\n",
      "[_Taking the citizens._]\n",
      "\n",
      "GLOUCESTER.\n",
      "O Titus’st thou cease and of Swear, my dear lord,\n",
      "ry. How did not guard his lord III. What, how weary now? Have’t.\n",
      "And Henry’s my Grum Petruchio. Is the cold?\n",
      "\n",
      "PERCY.\n",
      "My father.\n",
      "\n",
      " Enter Troilus!\n",
      "\n",
      "SIRAS.\n",
      "Were the succession deeper, Nurse.\n",
      "\n",
      "TITUS.\n",
      "oving cause here now a, York, sir, I did whipped in. O-hell!\n",
      "\n",
      "ARON.\n",
      "Caesar, my lord, cousin, I, Cassio Accogue. What wouldst not my lord.\n",
      "\n",
      "LONGAVIA.\n",
      "Well, let is my lord, now, I thought\n",
      "Snests be corrupt this praise in my angry, I, an’t.\n",
      "\n",
      "WORLANDO, now, tell me well that he is, Emilia.\n",
      "\n",
      "SUFFOLK.\n",
      "Go, go of yours.\n",
      "\n",
      "KING HENRY.\n",
      "Hail, Isabel! Whipholus,\n",
      "Or wake Talbot shows me leave—\n",
      "In the first graceful honey me left pap, very sullen: to death.\n",
      "And so! Why art day, impour and good manners are more doth slit, let\n",
      "When she, where they are made?\n",
      "\n",
      "BERTRAM.\n",
      "It needs shent a shaught yonder Glend\n",
      "Of the pitiful in giver.\n",
      "\n",
      "ADRIANA.\n",
      "By faith, lightly damneth the right, daughter of Derby.\n",
      "\n",
      "GLOUCESTER.\n",
      "Of such Nestor, is my mother, yet I have a month surprised.\n",
      "O Diom of thy plea.\n",
      "If I shall guard the haste I bear ’tis little regard\n",
      "A greater sharp face yourself.\n",
      "But shall make these do think a heavy chances life,\n",
      "Even for your hands by these things enter clouded and did: but doth.\n",
      "\n",
      "LAERTES.\n",
      "A bitter potark, look to follow,\n",
      "To stop, like English for weep more abrook tricks, Hero? Is his son are round are near by those own precinct\n",
      "Lookly:\n",
      "Striving of wrath of France\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Contents that holds this fellow o’er.\n",
      "\n",
      "MISTRESS PAGE.\n",
      "My lord.\n",
      "\n",
      "SIR PETITIONEROSWOM.\n",
      "Not well is but Casca? How now the world says Answer it loose?\n",
      "\n",
      "DENSends,\n",
      "That is the end:Made me not falling.\n",
      "\n",
      "WALD.\n",
      "The Messenger.\n",
      "\n",
      "Sovereign war?\n",
      "\n",
      "THERSITES.\n",
      "No more, good report not the maid.\n",
      "\n",
      "BEROWNE.\n",
      "Ay, no grace the parleary embracusa, he is!\n",
      "I understand to Rossillon and say you two answers inclined as a liege, and that art\n",
      "Over this!\n",
      "Paris’s grace, humble true, takes off, and swear\n",
      "Throws his body for Hamlet or so lie magistrat the side,\n",
      "Grim-regitting all thy chamber window,\n",
      "With precious the danger, when our purposes is in the both your instruments\n",
      "Of every world in this eagerest-scain of England is as his chair,\n",
      "In his peers, women, clear in the whole senses,\n",
      "andowed isle, and “Who dareemy”.\n",
      "\n",
      " [_Whose old glad and confound! Look you between take hence.\n",
      "The trumpetors, you, comfortably; and Trinculo\n",
      "Mroclus.\n",
      "\n",
      "KING.\n",
      "No more.\n",
      "\n",
      "THUR.\n",
      "Surend, my lords, man of fortune\n",
      "Should eleven this eyes complain;\n",
      "And hence or counsel I tarreputation speak error the sanctuary.\n",
      "\n",
      "IAGO.\n",
      "O, whine springs me wrong!\n",
      "\n",
      " you both:\n",
      "It should you give usameèd blue heir of them hasty murderers, good sadness,\n",
      "Only much with roses.\n",
      "\n",
      "DESDEMONA.\n",
      "Why, sweet Frank, lie stalkless father, if you have it come, you must leave not make me for our wives;\n"
     ]
    }
   ],
   "source": [
    "token = encoder.encode('\\n')\n",
    "idx = torch.tensor([token], dtype=torch.long)\n",
    "for token in gpt.generate(idx, max_new_tokens=1000):\n",
    "    print(encoder.decode(token[0].tolist()), end='', flush=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
