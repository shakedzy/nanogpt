{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "from tqdm import tqdm\n",
    "from torch import nn\n",
    "from typing import cast\n",
    "from nanogpt.data import Data\n",
    "from nanogpt.encoder import Encoder\n",
    "from nanogpt.gpt import NanoGPT\n",
    "from nanogpt.blm import BigramLanguageModel\n",
    "from nanogpt.utils import path_to_resource_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x11bc38bd0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.set_default_device('mps')  # Running on a Mac\n",
    "torch.manual_seed(1337)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(path_to_resource_file(\"tiny_shakespeare.txt\"), \"r\") as f:\n",
    "    text = f.read()\n",
    "\n",
    "encoder = Encoder(text)\n",
    "data = Data(torch.tensor(encoder.encode(text), dtype=torch.long), split=.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def estimate_loss(model: nn.Module, data: Data, batch_size: int, block_size: int):\n",
    "    out = {}\n",
    "    model.eval()\n",
    "    for split in ['train', 'test']:\n",
    "        eval_iters = 100\n",
    "        losses = torch.zeros(eval_iters)\n",
    "        for k in range(eval_iters):\n",
    "            X, Y = data.get_batch(split, batch_size=batch_size, block_size=block_size)  # type: ignore\n",
    "            _, loss = model(X, Y)\n",
    "            losses[k] = loss.item()\n",
    "        out[split] = losses.mean()\n",
    "    model.train()\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs:\n",
      "torch.Size([4, 8])\n",
      "tensor([[53, 59,  6,  1, 58, 56, 47, 40],\n",
      "        [49, 43, 43, 54,  1, 47, 58,  1],\n",
      "        [13, 52, 45, 43, 50, 53,  8,  0],\n",
      "        [ 1, 39,  1, 46, 53, 59, 57, 43]], device='mps:0')\n",
      "targets:\n",
      "torch.Size([4, 8])\n",
      "tensor([[59,  6,  1, 58, 56, 47, 40, 59],\n",
      "        [43, 43, 54,  1, 47, 58,  1, 58],\n",
      "        [52, 45, 43, 50, 53,  8,  0, 26],\n",
      "        [39,  1, 46, 53, 59, 57, 43,  0]], device='mps:0')\n",
      "---------\n",
      "Loss: 4.945623397827148\n",
      "torch.Size([4, 8, 65])\n"
     ]
    }
   ],
   "source": [
    "xb, yb = data.get_batch('train', 4, 8)\n",
    "print('inputs:')\n",
    "print(xb.shape)\n",
    "print(xb)\n",
    "print('targets:')\n",
    "print(yb.shape)\n",
    "print(yb)\n",
    "\n",
    "print('---------')\n",
    "blm = BigramLanguageModel(len(encoder))\n",
    "logits, loss = blm(xb, yb)\n",
    "print('Loss:', loss.item())\n",
    "print(logits.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Uoas&OmKdYMjGTEzqkPVQNRM.OyOdUfZE&exKZ:Ioc-skcECOIiuex zgZEAQ;tvrYvMtVcAQYDXOhodng&?onyOAvQYoeKyLXDL\n"
     ]
    }
   ],
   "source": [
    "idx = torch.zeros((1, 1), dtype=torch.long).to('mps')\n",
    "print(encoder.decode(blm.generate(idx, max_new_tokens=100)[0].tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:12<00:00, 812.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.4964492321014404\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Training\n",
    "optimizer = torch.optim.AdamW(blm.parameters(), lr=1e-3)\n",
    "for _ in tqdm(range(10000)):\n",
    "    xb, yb = data.get_batch('train', batch_size=32, block_size=8)\n",
    "    logits, loss = blm(xb, yb)\n",
    "    loss = cast(torch.Tensor, loss)\n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "print(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "HEayo in mpery way avend oubur'er sickes bokecard dhiceny\n",
      "\n",
      "He tw el fe oupise he, lbustselownthers;\n",
      "\n"
     ]
    }
   ],
   "source": [
    "idx = torch.zeros((1, 1), dtype=torch.long).to('mps')\n",
    "print(encoder.decode(blm.generate(idx, max_new_tokens=100)[0].tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [13:20<00:00, 12.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train': tensor(1.6927, device='mps:0'), 'test': tensor(1.8628, device='mps:0')}\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "context_length = 32\n",
    "\n",
    "gpt = NanoGPT(vocab_size=len(encoder), embedding_size=64, context_length=context_length, num_heads=4, num_blocks=4, dropout=.2)\n",
    "\n",
    "# Training\n",
    "optimizer = torch.optim.AdamW(gpt.parameters(), lr=1e-3)\n",
    "for _ in tqdm(range(10000)):\n",
    "    xb, yb = data.get_batch('train', batch_size=batch_size, block_size=context_length)\n",
    "    logits, loss = gpt(xb, yb)\n",
    "    loss = cast(torch.Tensor, loss)\n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "print(estimate_loss(gpt, data, batch_size=batch_size, block_size=context_length))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "he'sll ove hand the arr flosttill sike calme I be mang tas: ong acim, said;\n",
      "And nd ightan; that y you befr.\n",
      "\n",
      "BOWhat just. OFIGHare M:\n",
      "father mosty ke.\n",
      "AUFIfirst a\n",
      "LO:\n",
      "How I somulight my ove.'\n",
      "\n",
      "Cousild Lady, in this hatskford;\n",
      "Belifers king ththey word: thouse lawful.\n",
      "I The didiest mine t a anigale, kneed wish be leengetep of hirm, if swort.\n",
      "\n",
      "KING HEDWASTINRD IONGS:\n",
      "Poul Lance, strance! Fraworch greors the with grive hath morberbianince on b corfume to sweell trnown hon sunh,\n",
      "And getttlle mee shat steat somory con onfor heve drads,\n",
      "Furbth that willt to nountner to thy ell adskele man faice from per'd,\n",
      "Oxne son, oigcty he na Afingal to t woringh;\n",
      "nnoe roncie wen thin ford gealins ton her me replil dic leiges\n",
      "Taby bas I lloord, mee meast my willl down!\n",
      "\n",
      "Some more fleak'd the crseanged young be this disentenge him!\n",
      "\n",
      "Cord hodat Give esill aggod endoe time\n",
      "Ty bergat s:\n",
      "The hart pod it He'e 's is tpriecesnts\n",
      "That in will 'd, be I so aisgn im;\n",
      "And sthat aske shont\n",
      "In gof n wings yours be the E"
     ]
    }
   ],
   "source": [
    "idx = torch.zeros((1, 1), dtype=torch.long)\n",
    "for token in gpt.generate(idx, max_new_tokens=1000):\n",
    "    print(encoder.decode(token[0].tolist()), end='', flush=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
